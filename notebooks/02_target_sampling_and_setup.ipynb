{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79bd0915",
   "metadata": {},
   "source": [
    "## Notebook 2 : 02_target_sampling_and_setup.ipynb\n",
    "\n",
    "#### Author: Satveer Kaur\n",
    "#### Date: 2025-10-19\n",
    "\n",
    "#### Notebook Purpose:\n",
    "This notebook initiates the analytical development phase of the project, focusing on preparing the **clean data for efficient risk modeling and reporting**. This requires two critical actions: **Target Variable Definition** and **Analytical Sampling**.\n",
    "\n",
    "**Primary Objective:** To transform the structurally clean data into a format ready for quantitative risk assessment and feature engineering.\n",
    "\n",
    "**Key Deliverables:**\n",
    "1. **Binary Target Variable**(`is_default`): Formal consolidation of the `loan_status` text categories into a 0/1 outcome (non-default/default) that defines the risk metric.\n",
    "2. **Representative Sample:** Creation of a statistically valid subset of the full data (2.26M records) to ensure development workflows (EDA, binning, visualization) are efficient and rapid.\n",
    "\n",
    "**Input:** `clean_data_for_sampling.csv` (Output from Notebook 01).\n",
    "\n",
    "**Output:** `sample_data_for_development.csv` (Input for Notebook 03)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c264e48c",
   "metadata": {},
   "source": [
    "#### 1. Setup and Data Ingestion\n",
    "**Purpose**: To initialize the environment, enforce professional display standards, and securely load the clean and stabilized dataset (`clean_data_for_sampling.csv`) from the previous notebook. This action establishes the primary DataFrame (`df`) for all subsequent analytical transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70a71ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean data loaded successfully, Total records: 2,260,668\n",
      "Initial Columns: 102\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split  # for stratified sampling\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Load cleaned datasets\n",
    "df= pd.read_csv('../data/processed/clean_data_for_sampling.csv', low_memory=False, parse_dates=['issue_date'])\n",
    "\n",
    "print(f'Clean data loaded successfully, Total records: {len(df):,.0f}')\n",
    "print(f'Initial Columns: {df.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bebac81",
   "metadata": {},
   "source": [
    "#### 2. Define the Target Variable `is_default`\n",
    "**Purpose:** To perform the critical analytical transformation of the `loan_status` feature by consolidating various terminal text statuses into a definitive binary target variable (`is_default`). This step formalizes the criteria for loan non-performance (default = 1) versus acceptable performance (non-default = 0), which is essential for quantifying and modeling credit risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c81e0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Current', 'Charged Off', 'In Grace Period',\n",
       "       'Late (31-120 days)', 'Late (16-30 days)', 'Default',\n",
       "       'Does not meet the credit policy. Status:Fully Paid',\n",
       "       'Does not meet the credit policy. Status:Charged Off'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b58415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable \"is_default\" created\n",
      "Observed Default Rate (ODR) in the full portfolio: 11.92%\n"
     ]
    }
   ],
   "source": [
    "# Default groups \n",
    "default_statuses = [\n",
    "    'Charged Off', 'Default', 'Does not meet the credit policy. Status:Charged Off'\n",
    "]\n",
    "\n",
    "# Create is_default columns: 1 if status in default list, 0 otherwise\n",
    "df['is_default'] =  df['loan_status'].apply(\n",
    "    lambda x : 1 if x in default_statuses else 0\n",
    ")\n",
    "\n",
    "default_rate = df['is_default'].mean() * 100\n",
    "print('Target Variable \"is_default\" created')\n",
    "print(f'Observed Default Rate (ODR) in the full portfolio: {default_rate:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da46455c",
   "metadata": {},
   "source": [
    "#### 3. Analytical Sampling (Stratified)\n",
    "**Purpose:**  \n",
    "To increase analytical efficiency and speed up iterative development (EDA, feature engineering) by creating a **statistically representative** 10% **sample** of the full dataset. The stratified approach guarantees the sample's **Observed Default Rate (ODR)** exactly matches the full population's ODR, ensuring reliable feature validation without introducing bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c1908aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Sample Created (10% of full data)\n",
      "Sample Size: 226,066 rows\n",
      "Full Portfolio ODR: 11.9151%\n",
      "Sample ODR: 11.9151%\n"
     ]
    }
   ],
   "source": [
    "# Stratified sampling using train_test_split\n",
    "df_sample, df_remainder = train_test_split(\n",
    "    df,\n",
    "    test_size=0.9, # keep 10% for sample \n",
    "    stratify=df['is_default'], # stratify by the binary target\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# verification\n",
    "full_default_rate = df['is_default'].mean() * 100\n",
    "sample_default_rate = df['is_default'].mean() * 100\n",
    "\n",
    "print('Stratified Sample Created (10% of full data)')\n",
    "print(f'Sample Size: {len(df_sample):,.0f} rows')\n",
    "print(f'Full Portfolio ODR: {full_default_rate:.4f}%')\n",
    "print(f'Sample ODR: {sample_default_rate:.4f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7f76de",
   "metadata": {},
   "source": [
    "#### 4. Checkpoint and Export Sample Data\n",
    "**Purpose:** To save the development sample (`df_sample`) which includes the newly created binary target variable, to the processed data folder. This file will serve as the input for all subsequent exploratory and feature engineering work in Notebook 03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab007cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 2 Complete. Development sample saved.\n"
     ]
    }
   ],
   "source": [
    "df_sample.to_csv('../data/processed/sample_data_for_development.csv', index=False)\n",
    "print('Notebook 2 Complete. Development sample saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8137e79d",
   "metadata": {},
   "source": [
    "#### 5. Summary and Next Steps\n",
    "##### Summary\n",
    "1. **Target Definition:** Successfully defined the binary analytical target variable, is_default, by consolidating terminal loan_status categories.\n",
    "2. **Observed Default Rate (ODR):** The full portfolio's ODR was calculated at `11.9151 %`\n",
    "3. **Analytical Efficiency:** A statistically robust 10% sample was created using stratified sampling based on `is_default` to ensure zero sampling bias.\n",
    "4. **Sample Validation:** The sample's ODR was confirmed to be an exact match for the full portfolio's ODR, validating its use for all iterative development.\n",
    "\n",
    "##### Next Steps: Feature Development and Exploration\n",
    "The data is clean, the target is defined, and a representative sample is ready. The focus now shifts to exploring the data and developing the final risk segmentation features.\n",
    "\n",
    "**Action:** Proceed to Notebook 03 to begin the iterative exploration phase.\n",
    "1. **Exploratory Data Analysis (EDA):** Perform in-depth visualization of key risk features (FICO, DTI, Income) against the is_default target.\n",
    "2. **Feature Engineering:** Develop and finalize the binning logic for the primary risk drivers to create the auditable segmentation features.\n",
    "3. **Monotonicity Validation:** Generate charts and tables to formally validate the consistent separation of risk provided by the engineered features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
